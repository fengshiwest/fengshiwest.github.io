I"
<h2 id="论文笔记-visualizing-and-understanding-convolutional-networks">论文笔记: Visualizing and Understanding Convolutional Networks</h2>

<h3 id="本文贡献">本文贡献</h3>

<ol>
  <li>介绍了一种可视化技术，揭示了在模型的任意层激发单独特征映射的输入促进因素。</li>
  <li>在训练过程中观察特征的演变，并诊断模型的潜在问题。我们提出的可视化技术使用多层反卷积网络(deconvnet)将特征激活投影回输入像素空间。</li>
  <li>对分类器输出进行灵敏度分析，通过遮挡输入图像的部分，揭示场景的哪些部分对分类是重要的。</li>
</ol>

<h2 id="论文笔记deep-inside-convolutional-networks-visualising-image-classification-models-and-saliency-maps">论文笔记：Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</h2>

<h3 id="本文贡献-1">本文贡献</h3>

<ol>
  <li>提出显著性图(Saliency Maps)</li>
</ol>

<h3 id="显著性图原理">显著性图原理</h3>

<p>计算每一个像素点的导数，表示该点的微小改变对于结果的影响程度，从而看可以得知该像素点对于图像分类结果的影响。</p>

<h3 id="代码实现">代码实现</h3>

<p><a href="https://github.com/wmn7/ML_Practice/blob/master/2019_07_08/Saliency%20Maps/Saliency%20Maps%20Picture.ipynb">Saliency Maps ipynb</a></p>

<h2 id="cnn-explainer">CNN Explainer</h2>

<p><a href="https://poloclub.github.io/cnn-explainer/">演示地址</a></p>

<p><a href="https://github.com/poloclub/cnn-explainer">Github</a></p>

<h2 id="对cnn各层作用的理解">对CNN各层作用的理解</h2>

<h3 id="输入层">输入层</h3>

<p>对于RGB图像，输入层有R、G、B三个通道；对于灰度图像，输入层只有单通道。</p>

<h3 id="卷积层">卷积层</h3>

<p>参数：</p>

<p>Padding: 补充图像的边缘部分，一般补0</p>

<p>Kernel Size: 卷积核大小</p>

<p>Stride: 卷积核滑动步长</p>

<h3 id="激活函数">激活函数</h3>

<p>ReLU: 增加模型的非线性</p>

<p>（什么是非线性？一阶导数非常数，虽然ReLU在大于0和小于0部分均为线性，但是组合起来为非线性。）</p>

<p>Softmax: 使CNN的输出之和为1</p>

<h3 id="池化层">池化层</h3>

<p>减少网络空间范围，从而降低网络的参数和计算量</p>

<h2 id="激活层可视化">激活层可视化</h2>

<p><a href="https://yosinski.com/deepvis">项目地址</a></p>

<h2 id="参考文献">参考文献</h2>

<p>[1] Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson. Understanding neural networks through deep visualization. Presented at the Deep Learning Workshop, International Conference on Machine Learning (ICML), 2015.</p>
:ET